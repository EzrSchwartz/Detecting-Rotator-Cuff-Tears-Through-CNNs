{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Main.Py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create dataloader\n",
    "    dataset = Random3DDataset()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "    \n",
    "    # Example of accessing the data\n",
    "    for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "        print(f\"Batch {batch_idx}\")\n",
    "        print(f\"Data shape: {data.shape}\")  # Should be (batch_size, 1, depth, height, width)\n",
    "        print(f\"Labels: {labels}\")\n",
    "        \n",
    "        if batch_idx == 0:  # Just print first batch\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transferModel(1, random(1000), random(1000))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clymer.Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Copy of the top randomly initialized model architecture developed in the previous paper\n",
    "class RandomInitModelReplica(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RandomInitModelReplica, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=32, kernel_size=(3, 3,3), stride=(1, 1,1), padding=(1, 1,1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(2, 2,2), stride=(2, 2,2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(in_channels=32, out_channels=32, kernel_size=(3, 3,3), stride=(1,1,1), padding=(1, 1,1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2,2), stride=2,padding=(1,0,0), ceil_mode=False)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=self._get_fc_input_size(), out_features=16)\n",
    "        self.fc2 = nn.Linear(in_features=16, out_features=2)\n",
    "      \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "    def _get_fc_input_size(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(1, 32, 4, 25, 25)\n",
    "            \n",
    "            x=self.pool2(x)\n",
    "            return x.numel()\n",
    "    def forward(self, x):\n",
    "        print(type(x))\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(f'conv1{x.shape}')\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        print(f'pool1{x.shape}')\n",
    "        x = self.conv2(x)\n",
    "        print(f'conv2{x.shape}')\n",
    "\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        print(f'pool2{x.shape}')\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x=self.fc1(x)\n",
    "        print(f'fc1{x.shape}')\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        print(f'fc2{x.shape}')\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Architecture of convolutional autoencoder used to transfer learned weights to glenoid labrum\n",
    "\n",
    "class Convolutional_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Convolutional_autoencoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels= 1, out_channels= 64, kernel_size= (3,3,3), stride=1,padding=1 )\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size= (2,2,2), stride= (2,2,2))\n",
    "        self.conv2 = nn.Conv3d(in_channels= 64, out_channels= 64,kernel_size= (3,3,3),stride=1,padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size= (2,2,2), stride= (2,2,2),padding=0, ceil_mode=True)\n",
    "\n",
    "\n",
    "        self.conv3 = nn.Conv3d(in_channels= 64, out_channels= 64, kernel_size= (3, 3, 3),stride= (1,1,1),padding=1)\n",
    "        self.upsample1 = nn.Upsample(size= (4,26,26))\n",
    "        self.conv4 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3, 3, 3), stride=(1, 1, 1),padding=1)\n",
    "        self. upsample2 = nn.Upsample(size= (8,52,52))\n",
    "        self.conv5 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3, 3, 3), stride=(1, 1, 1),padding=1)\n",
    "        self.output = nn.Conv3d(in_channels=64, out_channels=1, kernel_size=(1, 3, 3), stride=1)\n",
    "        \n",
    "#Output size: torch.Size([1, 1, 6, 50, 52])\n",
    "    def _get_fc_input_size(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(1, 1, 8, 50, 50 )\n",
    "            return x.numel()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(type(x))\n",
    "        print(f\"Input size: {x.size()}\")\n",
    "        x = self.conv1(x)\n",
    "        print(f\"Conv1 output size: {x.size()}\")\n",
    "        x= F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        print(f\"Pool1 output size: {x.size()}\")\n",
    "        x = F.relu(x)\n",
    "        x= self.conv2(x)\n",
    "        print(f\"Conv2 output size: {x.size()}\")\n",
    "        x = F.relu(x)\n",
    "        x=self.pool2(x)\n",
    "        print(f\"Pool2 output size: {x.size()}\")\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        print(f\"Conv3 output size: {x.size()}\")\n",
    "        x = F.relu(x)\n",
    "        x = self.upsample1(x)\n",
    "        print(f\"Upsample1 output size: {x.size()}\")\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        print(f\"Conv4 output size: {x.size()}\")\n",
    "        x = F.relu(x)\n",
    "        x = self.upsample2(x)\n",
    "        print(f\"Upsample2 output size: {x.size()}\")\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        print(f\"Conv5 output size: {x.size()}\")\n",
    "        x = F.relu(x)\n",
    "        x = self.output(x)\n",
    "        print(f\"Output size: {x.size()}\")\n",
    "        return x\n",
    "\n",
    "#Architecture of best performing shoulder labral tear classification model using transferred weights\n",
    "class ShoulderClassificationmodel(nn.Module,):\n",
    "    def __init__(self,TransferModel):\n",
    "        super(ShoulderClassificationmodel,self).__init__()\n",
    "        self.TransferModel = TransferModel\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels= 1, out_channels=64, kernel_size=(3,3,3),stride=1,padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size= (2,2,2), stride= (2, 2, 2),ceil_mode=True)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(in_channels= 64, out_channels= 64, kernel_size= (3, 3, 3),stride=1,padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size= (2, 2, 2), stride= (2, 2, 2), ceil_mode=True)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(in_channels= 64, out_channels= 64, kernel_size= (3, 3, 3), stride=1, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._get_fc_input_size(), out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=2)\n",
    "\n",
    "\n",
    "    def _get_fc_input_size(self):\n",
    "        # Define a dummy tensor with the shape of the expected input to the model\n",
    "        x = torch.randn(1, 64, 2, 13, 13)  # (batch_size, channels, depth, height, width)\n",
    "        \n",
    "        # Pass it through the convolutional layer to get the output size\n",
    "        x = self.conv3(x)\n",
    "        print(x.numel())\n",
    "        # Flatten the output and get the number of features for the fully connected layer\n",
    "        return x.numel() \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.TransferModel(x)\n",
    "        print(f\"Input size: {x.size()}\")\n",
    "        x = self.conv1(x)\n",
    "        print(f'conv1 output: {x.size()}')\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        print(f'pool1 output: {x.size()}')\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        print(f'conv2 output: {x.size()}')\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        print(f'pool2 output: {x.size()}')\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        print(f'conv3 output: {x.size()}')\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        print(f'flatten output: {x.size()}')\n",
    "        x=self.fc1(x)\n",
    "        print(f'fc1 output: {x.size()}')\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        print(f'fc2 output: {x.size()}')\n",
    "\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def randintModel(_numEpoch, _shoulderData):\n",
    "    numEpoch = _numEpoch\n",
    "    shoulderData = _shoulderData\n",
    "    model = RandomInitModelReplica()\n",
    "    for epoch in range(numEpoch):\n",
    "        for (data_input) in enumerate(shoulderData):\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "            optimizer.step()\n",
    "            torch.save(model.state_dict(), f'Path to where we save the models{epoch}')\n",
    "\n",
    "def transferModel(_numEpoch,_TransferDataLoader,_ShoulderDataLoader):\n",
    "    numEpoch = _numEpoch\n",
    "    TransferDataLoader = _TransferDataLoader\n",
    "    ShoulderDataLoader = _ShoulderDataLoader\n",
    "    model = Convolutional_autoencoder()\n",
    "    for epoch in range(numEpoch):\n",
    "        for batch_idx, (transfer_data, _) in enumerate(TransferDataLoader):\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through the autoencoder\n",
    "            _ = model(transfer_data)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "    # Now, use the trained autoencoder with the classification model\n",
    "            model2 = ShoulderClassificationmodel(model)\n",
    "            model2_optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "            for batch_idx, (data_input, labels) in enumerate(ShoulderDataLoader):\n",
    "                model2_optimizer.zero_grad()\n",
    "\n",
    "                outputs = model2(data_input)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "        \n",
    "                loss.backward()\n",
    "                model2_optimizer.step()\n",
    "\n",
    "                print(\"Epoch:\", epoch, \"Loss:\", loss.item())\n",
    "                torch.save(model2.state_dict(), f'Path to where we save the models')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class Random3DDataset(Dataset):\n",
    "    def __init__(self, num_samples=1000, depth=8, height=50, width=50, num_classes=2):\n",
    "        self.num_samples = num_samples\n",
    "        self.depth = depth\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            image = np.random.rand(depth, height, width)\n",
    "            \n",
    "            for d in range(depth):\n",
    "                center_y = np.random.randint(0, height)\n",
    "                center_x = np.random.randint(0, width)\n",
    "                radius = np.random.randint(5, 15)\n",
    "                \n",
    "                y, x = np.ogrid[-center_y:height-center_y, -center_x:width-center_x]\n",
    "                mask = x*x + y*y <= radius*radius\n",
    "                image[d][mask] = np.random.rand()\n",
    "                \n",
    "                noise = np.random.normal(0, 0.1, (height, width))\n",
    "                image[d] += noise\n",
    "            \n",
    "            image = (image - image.min()) / (image.max() - image.min())\n",
    "            \n",
    "            image_tensor = torch.FloatTensor(image).unsqueeze(0) \n",
    "            \n",
    "            label = np.random.randint(0, num_classes)\n",
    "            \n",
    "            self.data.append(image_tensor)\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "if __name__ == \"__Datasets__\":\n",
    "    # Create dataloader\n",
    "    dataset = Random3DDataset()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "    \n",
    "    # Example of accessing the data\n",
    "    for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "        print(f\"Batch {batch_idx}\")\n",
    "        print(f\"Data shape: {data.shape}\")  # Should be (batch_size, 1, depth, height, width)\n",
    "        print(f\"Labels: {labels}\")\n",
    "        \n",
    "        if batch_idx == 0:  # Just print first batch\n",
    "            break\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image_tensor = preProcessing(image_path)\n",
    "        if 'Tear' in image_path:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        return image_tensor, label\n",
    "class CustomDatasetUnsupervised(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image_tensor = preProcessing(image_path)\n",
    "        \n",
    "        return image_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def shoulders(Count):\n",
    "    dataset = CustomDatasetUnsupervised(R\"Path to shoulder data directory\")\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    for batch_idx, (data_input) in enumerate(dataloader):\n",
    "        if batch_idx == Count:\n",
    "            return dataloader\n",
    "def transfer(Count):\n",
    "    dataset = CustomDatasetUnsupervised(R\"Path to transfer data directory\")\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    for batch_idx, (data_input) in enumerate(dataloader):\n",
    "        if batch_idx == Count:\n",
    "            return dataloader\n",
    "def random(Count):\n",
    "    dataset = Random3DDataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    for batch_idx, (data_input) in enumerate(dataloader):\n",
    "        continue\n",
    "    return dataloader"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
